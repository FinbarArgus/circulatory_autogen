{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation and Calibration (3compartment -> no_arm_CVS)\n",
    "\n",
    "This notebook walks through the end-to-end workflow for generating, simulating, and calibrating a 3compartment model, then extending to a 0D-1D hybrid.\n",
    "\n",
    "## Big Picture Aim\n",
    "\n",
    "We want to be able to easily generate system models from CellML, tailored towards a specific use-case (number of vessels, 0D or 1D, complexity, etc), then calibrate the model to clinical data. Calibration is often difficult with a large parameter set, therefore, we use sensitivity analysis to find the most important parameters to calibrate.\n",
    "\n",
    "## Steps overview\n",
    "1. Set up imports and paths.\n",
    "2. Open vessel array file for 3compartment (switch to no_arm_CVS) in PhLynx.\n",
    "3. Generate CellML model from PhLynx (saved to Downloads).\n",
    "4. Load the model with `SimulationHelper`.\n",
    "5. Plot ground-truth data vs. uncalibrated outputs.\n",
    "6. Add arm vessels in PhLynx and regenerate. (We need arms to compare against finger pressure measurement!)\n",
    "7. Set the ground truth data for calibration.\n",
    "8. Create a parameter identification object from Python.\n",
    "9. Run sensitivity analysis over a large parameter set.\n",
    "10. View sensitivity analysis plots.\n",
    "11. Add an extra feature to fit to.\n",
    "12. Choose the most influential parameters (e.g., top 2).\n",
    "13. Run parameter identification (genetic algorithm).\n",
    "14. Review calibration outputs.\n",
    "15. Calculate PWV with the 0D model.\n",
    "16. Switch selected vessels to 1D and generate C++ model.\n",
    "17. Run the C++ model.\n",
    "18. Load and plot 0D-1D hybrid results.\n",
    "19. Compare PWV for 0D vs 0D-1D.\n",
    "20. Concise-call hints (commented).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![optional caption](diagram_cvs_model_without_left_arm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Set up imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Core imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use('module://ipykernel.pylab.backend_inline')\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import opencor as oc\n",
    "except:\n",
    "    print('opencor not available, open this jupyter notebook with a python version that has opencor installed')\n",
    "    exit()\n",
    "\n",
    "# TODO check if needed\n",
    "def series_to_constant(func):\n",
    "    func.series_to_constant = True\n",
    "    return func\n",
    "\n",
    "print(\"Imports done\")\n",
    "\n",
    "# USER TO CHANGE: Make sure this is your path to the circualatory_autogen tutorial\n",
    "project_root = Path(\"/home/farg967/Documents/git_projects/circulatory_autogen\")\n",
    "#################### TODO make this automatic in Docker ####################################\n",
    "\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "# Set up paths\n",
    "resources_dir = project_root / \"resources\" \n",
    "generated_models_dir = project_root / \"generated_models\"\n",
    "param_id_output_dir = project_root / \"param_id_output\"\n",
    "this_dir = project_root / \"tutorial\" / \"interactive\"\n",
    "downloads_dir = Path.home() / \"Downloads\"\n",
    "\n",
    "print(\"Paths done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Open vessel array in PhLynx (manual) to visualise the model\n",
    "\n",
    "- Open the 3compartment  vessel array in PhLynx [https:/phlynx.com].\n",
    "- You could also modify, create, and rearrange modules in PhLynx (see tutorial/interactive/image_to_hemodynamics.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Get default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.utility_funcs import get_default_inp_data_dict\n",
    "import pprint\n",
    "# Model identifiers\n",
    "model_name = \"cvs_model\"\n",
    "# file_prefix = \"3compartment\" \n",
    "file_prefix = model_name+\"_0d\" \n",
    "input_param_file = f\"{file_prefix}_parameters.csv\"\n",
    "\n",
    "# Base user inputs (this shows all the settings that can be changed)\n",
    "inp_data_dict = get_default_inp_data_dict(file_prefix, input_param_file, resources_dir)\n",
    "\n",
    "# TEMPORARY FOR THIS TUTORIAL\n",
    "inp_data_dict['DEBUG'] = True\n",
    "\n",
    "print('inp_data_dict set')\n",
    "pprint.pprint(inp_data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.script_generate_with_new_architecture import generate_with_new_architecture\n",
    "import shutil\n",
    "\n",
    "# Generate directly from resources CSVs\n",
    "success = generate_with_new_architecture(inp_data_dict=inp_data_dict)\n",
    "if not success:\n",
    "    raise RuntimeError(\"Model generation failed\")\n",
    "else:\n",
    "    print('Model generation successful')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Load the model with SimulationHelper\n",
    "\n",
    "Use the solver wrapper to load the CellML model and prepare a simulation helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solver_wrappers import get_simulation_helper_from_inp_data_dict\n",
    "\n",
    "# Simulation settings\n",
    "inp_data_dict[\"sim_time\"] = 2 # the 2 seconds we care about\n",
    "inp_data_dict[\"pre_time\"] = 20.0 # simulate for 20 seconds to get to periodic steady state\n",
    "\n",
    "sim_helper = get_simulation_helper_from_inp_data_dict(inp_data_dict)\n",
    "\n",
    "# Run once and plot a few representative variables\n",
    "sim_helper.run()\n",
    "variables_to_plot = [\n",
    "    \"venous_svc/u\",\n",
    "    \"A_aorta_ascending_1/v\",\n",
    "    \"A_aorta_ascending_1/u\",\n",
    "    \"heart/u_rv\",\n",
    "]\n",
    "\n",
    "y = sim_helper.get_results(variables_to_plot, flatten=True)\n",
    "t = sim_helper.get_time()\n",
    "\n",
    "##### Plotting #####\n",
    "\n",
    "plot_dir = Path(param_id_output_dir) / \"quicklooks\"\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, sharex=True, figsize=(8, 6))\n",
    "axs = axs.flatten()\n",
    "for idx, (ax, series, name) in enumerate(zip(axs, y, variables_to_plot)):\n",
    "    ax.plot(t, series)\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"uncalibrated_outputs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Plot ground-truth data vs uncalibrated outputs\n",
    "\n",
    "Load the ground-truth data and compare it to the uncalibrated simulation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update with your ground-truth data file\n",
    "# Example assumes a CSV with a time column and measurement columns\n",
    "\n",
    "ground_truth_file = os.path.join(this_dir, \"resources\", \"aorta_pressure_temp.txt\")\n",
    "if os.path.exists(ground_truth_file):\n",
    "    gt = pd.read_csv(ground_truth_file, sep=\"\\t\")\n",
    "\n",
    "    time_col = \"time_s\"\n",
    "    var_col = \"pressure_mmHg\"\n",
    "\n",
    "    time_gt = gt[time_col].to_numpy()\n",
    "    pressure_pa = gt[var_col].to_numpy() * 133.322  # mmHg -> Pa\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(time_gt, pressure_pa, label=\"ground truth\")\n",
    "    plt.plot(t, y[2], label=\"uncalibrated\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Pressure [Pa]\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Ground-truth file not found: {ground_truth_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) (SKIP THIS FOR NOW) Add arm vessels in PhLynx (manual)\n",
    "\n",
    "- Add arm vessels in PhLynx.\n",
    "- Regenerate the CellML model.\n",
    "- If you exported a new CellML file, re-run the copy/generation cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Create a parameter identification object which will be used to set up your calibration problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from param_id.paramID import CVS0DParamID\n",
    "\n",
    "# first create a a param id object which will be used to set up out calibration problem\n",
    "solver_info = {\n",
    "    \"pre_time\": 1.0,\n",
    "    \"sim_time\": 2.0,\n",
    "    \"dt_solver\": 0.01,\n",
    "}\n",
    "\n",
    "inp_data_dict['solver_info'] = solver_info\n",
    "\n",
    "param_id = CVS0DParamID.init_from_dict(inp_data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Set the observable data that you want to calibrate towards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.obs_data_helpers import ObsDataCreator\n",
    "\n",
    "# now create the obs data creator object for creating a dictionary that contains the data you will fit towards\n",
    "obs_data_creator = ObsDataCreator()\n",
    "\n",
    "# Protocol info (this defines your times and changes of inputs in the experiment)\n",
    "pre_times = [[20]]\n",
    "sim_times = [[time_gt[-1]]]\n",
    "obs_dt = time_gt[1]-time_gt[0]\n",
    "params_to_change = {}\n",
    "obs_data_creator.add_protocol_info(pre_times, sim_times, params_to_change)\n",
    "\n",
    "# add an entry for just fitting the mean of the pressure\n",
    "entry = {\n",
    "    \"variable\": \"P aortic root mean\",\n",
    "    \"name_for_plotting\": \"P_{aoMean}\",\n",
    "    \"operands\": [\"A_aorta_ascending_1/u\"],\n",
    "    \"operation\": \"mean\",\n",
    "    \"unit\": \"Pa\",\n",
    "    \"value\": np.mean(pressure_pa),\n",
    "    \"std\": 200, # assumed std of the mean pressure\n",
    "    \"obs_dt\": obs_dt,\n",
    "}\n",
    "obs_data_creator.add_data_item(entry)\n",
    "    \n",
    "\n",
    "obs_data_dict = obs_data_creator.get_obs_data_dict()\n",
    "\n",
    "# pprint.pprint(obs_data_dict)\n",
    "\n",
    "# now add the obs to the param id object\n",
    "param_id.set_ground_truth_data(obs_data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Create params_for_id.csv from Python\n",
    "\n",
    "- Define the parameter bounds for identification in a CSV file. Use the same schema as `resources/3compartment_params_for_id.csv`.\n",
    "- USER TASK: Write down what outputs of the CVS model (pressures? flows? features of pressure/flow traces, in which location?) you think each parameter will affect. Compare this with outputs later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These vessels will have their stiffness calibrated\n",
    "vessels_to_calibrate_stiffness = [\"K_tube_A_aorta_ascending_1\", \"K_tube_A_aorta_ascending_2\", \n",
    "                               \"K_tube_A_aorta_ascending_3\", \"K_tube_A_aorta_ascending_4\",\n",
    "                               \"K_tube_A_aortic_arch_1\", \"K_tube_A_aortic_arch_2\", \"K_tube_A_aortic_arch_3\"]\n",
    "\n",
    "# These vein compartments will have their compliance calibrated\n",
    "vein_compartments_to_calibrate_compliance = [\"venous_svc\", \"venous_ivc\", \n",
    "                                             \"venous_head_L_T\",\"venous_head_R_T\", \n",
    "                                             \"venous_arm_L_T\",\"venous_arm_R_T\",\n",
    "                                             \"venous_leg_L_T\",\"venous_leg_R_T\",\n",
    "                                             \"venous_trunk_C_T\"]\n",
    "\n",
    "params_for_id_dict = [\n",
    "    {\n",
    "        \"vessel_name\": \"global\",\n",
    "        \"param_name\": \"q_lv_init\", # we need to initialise blood volume somewhere, here we do it in the left ventricle for \n",
    "                                   # ease of implementation. This will be pumped around the body to \n",
    "                                   # give realistic volumes throughout the CVS.\n",
    "                                   # Think of this as a parameter that shifts the total blood volume.\n",
    "        \"min\": 400e-6,\n",
    "        \"max\": 2500e-6,\n",
    "        \"name_for_plotting\": \"q_{sbv}\",\n",
    "    },\n",
    "    {\n",
    "        \"vessel_name\": vessels_to_calibrate_stiffness,\n",
    "        \"param_name\": \"E\",  \n",
    "        \"min\": 8e+4,\n",
    "        \"max\": 4e+5,\n",
    "        \"name_for_plotting\": \"E_{ao}\",\n",
    "    },\n",
    "    {\n",
    "        \"vessel_name\": vein_compartments_to_calibrate_compliance,\n",
    "        \"param_name\": \"C\",\n",
    "        \"min\": 1e-7,\n",
    "        \"max\": 4e-7,\n",
    "        \"name_for_plotting\": \"C_{v}\",\n",
    "    }\n",
    "]\n",
    "\n",
    "print(params_for_id_dict)\n",
    "\n",
    "# now add the params to the param id object\n",
    "param_id.set_params_for_id(params_for_id_dict)\n",
    "\n",
    "# TODO the below to be implemented for easier calling. Feedback welcome.\n",
    "# param_id.add_param_for_id(module_name, param_name, min, max, name_for_plotting)\n",
    "# param_id.add_param_for_id(module_name, param_name, min, max, name_for_plotting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Sensitivity analysis\n",
    "\n",
    "Run Sobol sensitivity analysis over a large parameter set and save outputs to a defined directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensitivity_analysis.sensitivityAnalysis import SensitivityAnalysis\n",
    "import shutil\n",
    "\n",
    "sa_output_dir = Path(param_id_output_dir) / \"sensitivity\" / file_prefix\n",
    "if sa_output_dir.exists():\n",
    "    shutil.rmtree(sa_output_dir) # remove the directory if it exists\n",
    "sa_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "sa_options = {\n",
    "    \"method\": \"sobol\",\n",
    "    \"sample_type\": \"saltelli\",\n",
    "    \"num_samples\": 16, # change to 256\n",
    "    \"output_dir\": str(sa_output_dir),\n",
    "}\n",
    "\n",
    "sa_agent = SensitivityAnalysis.init_from_dict(inp_data_dict)\n",
    "\n",
    "\n",
    "\n",
    "sa_agent.set_ground_truth_data(obs_data_dict)\n",
    "sa_agent.set_params_for_id(params_for_id_dict)\n",
    "sa_agent.set_sa_options(sa_options)\n",
    "\n",
    "sa_agent.run_sensitivity_analysis(sa_options)\n",
    "sa_output_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) View the sensitivity analysis plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Display the plots from the sensitivity analysis\n",
    "plot_files = [file_path for file_path in sa_output_dir.glob(\"*.png\")]\n",
    "for plot_file in plot_files:\n",
    "    display(Image(filename=str(plot_file)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for Students\n",
    "\n",
    "- What do you think happens if you change the ranges for your parameters? How do we ensure these ranges are valid?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Now add your own extra feature to fit to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====  this is an example of how to add a custom feature to the obs data creator =====\n",
    "# this feature calculates the pressure at one point in time. \n",
    "# Modify this function to extract whatever feature you want! Max? Min? weights of a certain basis? Anything you want.\n",
    "\n",
    "# Create your own feature to fit to\n",
    "@series_to_constant\n",
    "def my_extra_feature(time, pressure, series_output=False):\n",
    "    if series_output: # needed for plotting the series in automatic plots\n",
    "        return pressure\n",
    "    half_idx = len(time) // 2\n",
    "    return pressure[half_idx]\n",
    "\n",
    "sa_agent.add_user_operation_func(my_extra_feature)\n",
    "param_id.add_user_operation_func(my_extra_feature)\n",
    "\n",
    "extra_entry = {\n",
    "    \"variable\": \"P aortic root half time\",\n",
    "    \"name_for_plotting\": \"$P_{aoHalf}$\",\n",
    "    \"operands\": [\"time\",\"A_aorta_ascending_1/u\"], # these need to correspond to the operands in my_extra_feature\n",
    "    \"operation\": \"my_extra_feature\",\n",
    "    \"unit\": \"Pa\",\n",
    "    \"value\": my_extra_feature(time_gt, pressure_pa), # this uses your function to get the value you want to fit to from the ground truth data\n",
    "    \"std\": 200, # assumed std of the pressure\n",
    "}\n",
    "\n",
    "obs_data_creator.add_data_item(extra_entry)\n",
    "obs_data_dict = obs_data_creator.get_obs_data_dict()\n",
    "obs_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sa_agent.set_ground_truth_data(obs_data_dict)\n",
    "\n",
    "# remove the old results before running.\n",
    "if sa_output_dir.exists():\n",
    "    shutil.rmtree(sa_output_dir) # remove the directory if it exists\n",
    "sa_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sa_agent.run_sensitivity_analysis(sa_options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display the plots from the sensitivity analysis\n",
    "plot_files = [file_path for file_path in sa_output_dir.glob(\"*.png\")]\n",
    "for plot_file in plot_files:\n",
    "    display(Image(filename=str(plot_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Choose influential parameters\n",
    "\n",
    "Review the sensitivity analysis outputs (plots/arrays) to choose the most influential parameters (e.g., top 2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: inspect SA outputs in sa_output_dir and pick top parameters\n",
    "# Example placeholder list:\n",
    "# most_influential_params = [\n",
    "#     \"global/q_lv_init\"\n",
    "# ]\n",
    "# most_influential_params\n",
    "\n",
    "most_influential_params = sa_agent.choose_most_impactful_params_sobol(top_n=1, index_type='ST', criterion='max', threshold=0.05, use_threshold=True)\n",
    "# TODO the below needs to be done in the function\n",
    "most_influential_param_names = [param.split(\"/\")[-1] for param in most_influential_params]\n",
    "most_influential_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) Parameter identification (genetic algorithm)\n",
    "\n",
    "Use the genetic algorithm to calibrate model parameters.\n",
    "\n",
    "$$\n",
    "\\theta^{\\star} = \\arg\\min_{\\theta \\in \\Theta} \\; \\sum_{i=1}^{N} w_i \\left\\lVert \\frac{z_i(\\theta) - \\hat{z_i}}{\\sigma_i} \\right\\rVert^2\n",
    "$$\n",
    "\n",
    "where $\\theta^{\\star}$ is the best fit parameter vector, $\\Theta$ is your parameter space, defined by the min and max you set in params_for_id_dict, $z_i$ are your output features, $\\hat{z_i}$ are your ground truths for those features, $\\sigma_i$ are your feature standard deviations, and $w_i$ are the weights for each feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from param_id.paramID import CVS0DParamID\n",
    "\n",
    "inp_data_dict[\"param_id_method\"] = \"genetic_algorithm\"\n",
    "param_id.set_param_id_method(inp_data_dict[\"param_id_method\"])\n",
    "\n",
    "# Optimiser options (adjust as needed)\n",
    "optimiser_options = {\n",
    "    \"num_calls_to_function\": 100,\n",
    "    \"cost_convergence\": 0.001,\n",
    "    \"max_patience\": 10,\n",
    "    \"cost_type\": \"MSE\",\n",
    "}\n",
    "\n",
    "param_id.set_optimiser_options(optimiser_options)\n",
    "param_id.set_ground_truth_data(obs_data_dict)\n",
    "\n",
    "# TODO the below needs to be done in the function (not visible to user)\n",
    "params_for_id_subset = [\n",
    "    entry for entry in params_for_id_dict\n",
    "    if entry[\"param_name\"] in most_influential_param_names\n",
    "]\n",
    "\n",
    "param_id.set_params_for_id(params_for_id_subset)\n",
    "\n",
    "# Run calibration\n",
    "param_id.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot best fit\n",
    "param_id.simulate_with_best_param_vals()\n",
    "param_id.plot_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Review calibration outputs\n",
    "\n",
    "The calibration process saves plots and arrays in the parameter ID output directory. Use this section to view the plots. You can also make your own plots with the saved outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(param_id.output_dir)\n",
    "print(\"Outputs saved to:\", output_dir)\n",
    "\n",
    "# Example: load best parameters\n",
    "best_params_path = output_dir / \"best_param_vals.npy\"\n",
    "if best_params_path.exists():\n",
    "    best_params = np.load(best_params_path)\n",
    "    best_params\n",
    "else:\n",
    "    print(\"best_param_vals.npy not found\")\n",
    "\n",
    "# Display the plots from the param id\n",
    "plot_files = [file_path for file_path in output_dir.glob(\"*.png\")]\n",
    "for plot_file in plot_files:\n",
    "    display(Image(filename=str(plot_file)))\n",
    "    \n",
    "\n",
    "# === Here you can make your own custom plots using saved outputs in output_dir ===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP TO IMPROVE CALIBRATION\n",
    "\n",
    "- We know that the arterial elastance is important for fitting pulse pressure. How would you create a feature that is sensitive to E but not to intial blood volume or venous compliance? \n",
    "\n",
    "- Try to improve the calibration pipeline by adding features to calibrate that aren't correlated (are close to orthogonal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15) STOP HERE FOR NOW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16) Switch selected vessels to 1D and generate C++ model\n",
    "\n",
    "Update vessel arrays for 1D coupling and regenerate a C++ model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vess_1d_list.extend(['A_axillary_L', 'A_brachial_L', 'A_radial_L', 'A_ulnar_L',\n",
    "                     'A_superficial_palmar_arch_L_1', 'A_superficial_palmar_arch_L_2',\n",
    "                     'A_comm_palmar_digital_L_1', 'A_comm_palmar_digital_L_2', 'A_comm_palmar_digital_L_3'])\n",
    "    \n",
    "convert_0d_to_1d(model_name_ext, resources_dir, input_param_file, folder_hyb=None, vess_1d_list=vess_1d_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17) Run the C++ model\n",
    "\n",
    "Use `subprocess` to run the compiled binary for the 0D-1D hybrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# TODO: update binary path and arguments\n",
    "cpp_run_dir = Path(inp_data_dict_cpp.get(\"cpp_generated_models_dir\", generated_models_dir / file_prefix))\n",
    "cpp_binary = cpp_run_dir / \"run_model\"  # placeholder\n",
    "\n",
    "# we need a step here to call the building of the cpp model\n",
    "# OR WE DO THIS IN TERMINAL AND PROVIDE INSTRUCTIONS\n",
    "\n",
    "\n",
    "# now run the cpp executable.\n",
    "if cpp_binary.exists():\n",
    "    result = subprocess.run([str(cpp_binary)], cwd=str(cpp_run_dir), capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "else:\n",
    "    print(f\"C++ binary not found: {cpp_binary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18) Load and plot 0D-1D hybrid results\n",
    "\n",
    "Load the hybrid outputs and compare them to the 0D results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update with real hybrid output file(s)\n",
    "hybrid_output_csv = cpp_run_dir / \"hybrid_outputs.csv\"\n",
    "\n",
    "if hybrid_output_csv.exists():\n",
    "    hybrid = pd.read_csv(hybrid_output_csv)\n",
    "    time_col = \"time\"  # TODO: update\n",
    "    hybrid_var = \"aortic_root/u\"  # TODO: update\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(t, y[2], label=\"0D\")\n",
    "    plt.plot(hybrid[time_col], hybrid[hybrid_var], label=\"0D-1D hybrid\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(hybrid_var)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Hybrid output not found: {hybrid_output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19) PWV comparison (0D vs 0D-1D)\n",
    "\n",
    "Compute PWV for the hybrid outputs and compare with the 0D model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute and compare PWV for hybrid outputs\n",
    "# pwv_hybrid = compute_pwv_from_hybrid(hybrid)\n",
    "# print(\"PWV 0D:\", pwv_0d)\n",
    "# print(\"PWV hybrid:\", pwv_hybrid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCOR",
   "language": "python",
   "name": "opencor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
