{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation and Calibration (3compartment -> no_arm_CVS)\n",
    "\n",
    "This notebook walks through the end-to-end workflow for generating, simulating, and calibrating a 3compartment model, then extending to a 0D-1D hybrid.\n",
    "\n",
    "## Steps overview\n",
    "1. Open vessel array file for 3compartment (switch to no_arm_CVS) in PhLynx.\n",
    "2. Generate CellML model from PhLynx (saved to Downloads).\n",
    "3. Set up `user_inputs_dict` for running the model.\n",
    "4. Load the model with `SimulationHelper`.\n",
    "5. Simulate the model and plot outputs.\n",
    "6. Plot ground-truth data vs. uncalibrated outputs.\n",
    "7. Add arm vessels in PhLynx and regenerate.\n",
    "8. Create `obs_data.json` from Python utilities.\n",
    "9. Create `params_for_id.csv` from Python.\n",
    "10. Run sensitivity analysis over a large parameter set.\n",
    "11. Choose the most influential parameters (e.g., top 2).\n",
    "12. Create a `param_id` object.\n",
    "13. Calibrate with the genetic algorithm.\n",
    "14. View auto-generated calibration plots.\n",
    "15. Create additional plots from saved outputs.\n",
    "16. Calculate PWV with the 0D model.\n",
    "17. Switch selected vessels to 1D.\n",
    "18. Generate a new C++ model with 1D vessels.\n",
    "19. Run the C++ model.\n",
    "20. Load 0D-1D hybrid results.\n",
    "21. Plot 0D-1D vs 0D results.\n",
    "22. Compute PWV for the hybrid and compare to 0D.\n",
    "\n",
    "> Update paths and filenames to match your environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Set up imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done\n",
      "Paths done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Core imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import opencor as oc\n",
    "except:\n",
    "    print('opencor not available, open this jupyter notebook with a python version that has opencor installed')\n",
    "    exit()\n",
    "\n",
    "print(\"Imports done\")\n",
    "\n",
    "# Ensure local src is importable\n",
    "project_root = Path(\"/home/farg967/Documents/git_projects/circulatory_autogen\")\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "# Set up paths\n",
    "resources_dir = project_root / \"resources\" # TODO: change to the downloads dir if using Phlynx output directly\n",
    "generated_models_dir = project_root / \"generated_models\"\n",
    "param_id_output_dir = project_root / \"param_id_output\"\n",
    "downloads_dir = Path.home() / \"Downloads\"\n",
    "\n",
    "print(\"Paths done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Open vessel array in PhLynx (manual)\n",
    "\n",
    "- Open the 3compartment  vessel array in PhLynx [LINK_TO_PHLYNX].\n",
    "- Save/export the vessel array so it is ready for CellML generation. [TO_REPLACE_WITH_GENERATED_CELLML_MODEL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Generate CellML in PhLynx (manual)\n",
    "\n",
    "- In PhLynx, generate the CellML model for the edited vessel array.\n",
    "- The exported file is typically saved to `~/Downloads`.\n",
    "- Note the exported filename (e.g., `3compartment.cellml`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_data_dict set\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model identifiers\n",
    "file_prefix = \"3compartment\"  \n",
    "input_param_file = f\"{file_prefix}_parameters.csv\"\n",
    "\n",
    "# Base user inputs (extend as needed later)\n",
    "inp_data_dict= {\n",
    "    \"file_prefix\": file_prefix,\n",
    "    \"input_param_file\": input_param_file,\n",
    "    \"resources_dir\": str(resources_dir),\n",
    "}\n",
    "\n",
    "print('inp_data_dict set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver must be an entry in the user_inputs.yaml file\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Generate directly from resources CSVs\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_with_new_architecture\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_data_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel generation failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/git_projects/circulatory_autogen/src/scripts/script_generate_with_new_architecture.py:28\u001b[0m, in \u001b[0;36mgenerate_with_new_architecture\u001b[0;34m(do_generation_with_fit_parameters, inp_data_dict)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_with_new_architecture\u001b[39m(do_generation_with_fit_parameters,\n\u001b[1;32m     25\u001b[0m                                    inp_data_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     27\u001b[0m     yaml_parser \u001b[38;5;241m=\u001b[39m YamlFileParser()\n\u001b[0;32m---> 28\u001b[0m     inp_data_dict \u001b[38;5;241m=\u001b[39m \u001b[43myaml_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_user_inputs_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_data_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs_path_needed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mdo_generation_with_fit_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_generation_with_fit_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     DEBUG \u001b[38;5;241m=\u001b[39m inp_data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEBUG\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     32\u001b[0m     file_prefix \u001b[38;5;241m=\u001b[39m inp_data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/git_projects/circulatory_autogen/src/parsers/PrimitiveParsers.py:191\u001b[0m, in \u001b[0;36mYamlFileParser.parse_user_inputs_file\u001b[0;34m(self, inp_data_dict, obs_path_needed, do_generation_with_fit_parameters)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver must be an entry in the user_inputs.yaml file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 191\u001b[0m     \u001b[43mexit\u001b[49m()\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     inp_data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m solver\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "from scripts.script_generate_with_new_architecture import generate_with_new_architecture\n",
    "import shutil\n",
    "\n",
    "# Generate directly from resources CSVs\n",
    "success = generate_with_new_architecture(False, inp_data_dict)\n",
    "if not success:\n",
    "    raise RuntimeError(\"Model generation failed\")\n",
    "else:\n",
    "    print('Model generation successful')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Load the model with SimulationHelper\n",
    "\n",
    "Use the solver wrapper to load the CellML model and prepare a simulation helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solver_wrappers import get_simulation_helper\n",
    "\n",
    "# Simulation settings\n",
    "sim_time = 2.0\n",
    "pre_time = 20.0 # simulate for 20 seconds to get to periodic steady state\n",
    "solver = inp_data_dict.get(\"solver\")\n",
    "solver_info = inp_data_dict.get(\"solver_info\", {})\n",
    "\n",
    "SimHelper = get_simulation_helper(\n",
    "    solver=solver,\n",
    "    model_type=inp_data_dict.get(\"model_type\"),\n",
    "    model_path=str(model_path),\n",
    ")\n",
    "\n",
    "sim_helper = SimHelper(\n",
    "    str(model_path),\n",
    "    dt=inp_data_dict[\"dt\"],\n",
    "    sim_time=sim_time,\n",
    "    solver_info=solver_info,\n",
    "    pre_time=pre_time,\n",
    ")\n",
    "\n",
    "# Run once and plot a few representative variables\n",
    "sim_helper.run()\n",
    "variables_to_plot = [\n",
    "    \"venous_svc/u\",\n",
    "    \"aortic_root/v\",\n",
    "    \"aortic_root/u\",\n",
    "    \"heart/u_rv\",\n",
    "]\n",
    "\n",
    "y = sim_helper.get_results(variables_to_plot, flatten=True)\n",
    "t = sim_helper.tSim - pre_time\n",
    "\n",
    "plot_dir = Path(param_id_output_dir) / \"quicklooks\"\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, sharex=True, figsize=(8, 6))\n",
    "axs = axs.flatten()\n",
    "for idx, (ax, series, name) in enumerate(zip(axs, y, variables_to_plot)):\n",
    "    ax.plot(t, series)\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"uncalibrated_outputs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Plot ground-truth data vs uncalibrated outputs\n",
    "\n",
    "Load the ground-truth data and compare it to the uncalibrated simulation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update with your ground-truth data file\n",
    "# Example assumes a CSV with a time column and measurement columns\n",
    "\n",
    "ground_truth_csv = resources_dir / f\"{file_prefix}_ground_truth.csv\"\n",
    "if ground_truth_csv.exists():\n",
    "    gt = pd.read_csv(ground_truth_csv)\n",
    "    time_col = \"time\"  # TODO: set correct column name\n",
    "    gt_var = \"aortic_root/u\"  # TODO: set correct variable column\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(gt[time_col], gt[gt_var], label=\"ground truth\")\n",
    "    plt.plot(t, y[2], label=\"uncalibrated\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(gt_var)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Ground-truth file not found: {ground_truth_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Add arm vessels in PhLynx (manual)\n",
    "\n",
    "- Add arm vessels in PhLynx.\n",
    "- Regenerate the CellML model.\n",
    "- If you exported a new CellML file, re-run the copy/generation cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.obs_data_helpers import ObsDataCreator\n",
    "\n",
    "# TODO: update with your real data source\n",
    "# Example: data = pd.read_csv(resources_dir / \"my_observations.csv\")\n",
    "# time = data[\"time\"].values\n",
    "\n",
    "obs_data_creator = ObsDataCreator()\n",
    "\n",
    "# Protocol info (edit to match your experiment design)\n",
    "pre_times = [pre_time]\n",
    "sim_times = [[sim_time]]\n",
    "params_to_change = {}\n",
    "obs_data_creator.add_protocol_info(pre_times, sim_times, params_to_change)\n",
    "\n",
    "# Prediction items (edit to match outputs you compare)\n",
    "obs_data_creator.add_prediction_item(\"aortic_root/u\", \"Pa\", 0)\n",
    "\n",
    "# Data items (fill with your actual observation series)\n",
    "# Example placeholder (replace with real data)\n",
    "entry = {\n",
    "    \"variable\": \"aortic_root/u\",\n",
    "    \"name_for_plotting\": \"P_ao\",\n",
    "    \"data_type\": \"series\",\n",
    "    \"operation\": None,\n",
    "    \"operands\": [\"aortic_root/u\"],\n",
    "    \"unit\": \"Pa\",\n",
    "    \"weight\": 1.0,\n",
    "    \"value\": [],  # TODO: fill with data values\n",
    "    \"std\": [],    # TODO: fill with std values\n",
    "    \"obs_dt\": inp_data_dict[\"dt\"],\n",
    "    \"experiment_idx\": 0,\n",
    "    \"subexperiment_idx\": 0,\n",
    "}\n",
    "obs_data_creator.add_data_item(entry)\n",
    "\n",
    "obs_data_path = resources_dir / f\"{file_prefix}_obs_data.json\"\n",
    "obs_data_creator.dump_to_path(str(obs_data_path))\n",
    "obs_data_dict = obs_data_creator.get_obs_data_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create params_for_id.csv from Python\n",
    "\n",
    "Define the parameter bounds for identification in a CSV file. Use the same schema as `resources/3compartment_params_for_id.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace with your full parameter set\n",
    "params_for_id_dict = [\n",
    "    {\n",
    "        \"vessel_name\": \"global\",\n",
    "        \"param_name\": \"q_lv_init\",\n",
    "        \"param_type\": \"const\",\n",
    "        \"min\": 200e-6,\n",
    "        \"max\": 1500e-6,\n",
    "        \"name_for_plotting\": \"q_{sbv}\",\n",
    "    },\n",
    "    {\n",
    "        \"vessel_name\": \"aortic_root\",\n",
    "        \"param_name\": \"C\",\n",
    "        \"param_type\": \"const\",\n",
    "        \"min\": 1e-9,\n",
    "        \"max\": 5e-8,\n",
    "        \"name_for_plotting\": \"C_{ao}\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(params_for_id_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Sensitivity analysis\n",
    "\n",
    "Run Sobol sensitivity analysis over a large parameter set and save outputs to a defined directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensitivity_analysis.sensitivityAnalysis import SensitivityAnalysis\n",
    "\n",
    "sa_output_dir = Path(param_id_output_dir) / \"sensitivity\" / file_prefix\n",
    "sa_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sa_options = {\n",
    "    \"method\": \"sobol\",\n",
    "    \"sample_type\": \"saltelli\",\n",
    "    \"num_samples\": 256,\n",
    "    \"output_dir\": str(sa_output_dir),\n",
    "}\n",
    "\n",
    "model_out_names = [\"aortic_root/u\", \"aortic_root/v\"]  # TODO: update\n",
    "\n",
    "sa_agent = SensitivityAnalysis(\n",
    "    file_prefix=file_prefix,\n",
    "    resources_dir=str(resources_dir),\n",
    "    model_out_names=model_out_names,\n",
    "    solver_info=solver_info,\n",
    ")\n",
    "\n",
    "sa_agent.set_ground_truth_data(obs_data_dict)\n",
    "sa_agent.set_params_for_id(params_for_id_dict)\n",
    "\n",
    "sa_agent.run_sensitivity_analysis(sa_options)\n",
    "sa_output_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Choose influential parameters\n",
    "\n",
    "Review the sensitivity analysis outputs (plots/arrays) to choose the most influential parameters (e.g., top 2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: inspect SA outputs in sa_output_dir and pick top parameters\n",
    "# Example placeholder list:\n",
    "most_influential_params = [\n",
    "    \"global/q_lv_init\",\n",
    "    \"aortic_root/C\",\n",
    "]\n",
    "most_influential_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Parameter identification (genetic algorithm)\n",
    "\n",
    "Use the genetic algorithm to calibrate model parameters.\n",
    "\n",
    "$$\n",
    "\\min_{\\theta \\in \\Theta} \\; \\sum_{i=1}^{N} w_i \\lVert y_i^{model}(\\theta) - y_i^{obs} \\rVert^2\n",
    "$$\n",
    "\n",
    "> Replace the objective above with your formal calibration problem as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from param_id.paramID import CVS0DParamID\n",
    "\n",
    "# Optimiser options (adjust as needed)\n",
    "optimiser_options = {\n",
    "    \"num_calls_to_function\": 10000,\n",
    "    \"cost_convergence\": 0.001,\n",
    "    \"max_patience\": 10,\n",
    "    \"cost_type\": \"MSE\",\n",
    "}\n",
    "\n",
    "param_id = CVS0DParamID(\n",
    "    model_path=str(model_path),\n",
    "    model_type=inp_data_dict[\"model_type\"],\n",
    "    param_id_method=inp_data_dict[\"param_id_method\"],\n",
    "    mcmc_instead=False,\n",
    "    file_prefix=file_prefix,\n",
    "    params_for_id_path=str(params_for_id_path),\n",
    "    param_id_obs_path=str(obs_data_path),\n",
    "    sim_time=sim_time,\n",
    "    pre_time=pre_time,\n",
    "    solver_info=solver_info,\n",
    "    dt=inp_data_dict[\"dt\"],\n",
    "    optimiser_options=optimiser_options,\n",
    "    DEBUG=inp_data_dict[\"DEBUG\"],\n",
    "    param_id_output_dir=str(param_id_output_dir),\n",
    "    resources_dir=str(resources_dir),\n",
    ")\n",
    "\n",
    "# Genetic algorithm settings (if applicable)\n",
    "if inp_data_dict[\"param_id_method\"] == \"genetic_algorithm\":\n",
    "    param_id.set_genetic_algorithm_parameters(optimiser_options[\"num_calls_to_function\"])\n",
    "\n",
    "# Run calibration\n",
    "param_id.run()\n",
    "\n",
    "# Plot best fit\n",
    "param_id.simulate_with_best_param_vals()\n",
    "param_id.plot_outputs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Review calibration outputs\n",
    "\n",
    "The calibration process saves plots and arrays in the parameter ID output directory. Use this section to generate additional figures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(param_id.output_dir)\n",
    "print(\"Outputs saved to:\", output_dir)\n",
    "\n",
    "# Example: load best parameters\n",
    "best_params_path = output_dir / \"best_param_vals.npy\"\n",
    "if best_params_path.exists():\n",
    "    best_params = np.load(best_params_path)\n",
    "    best_params\n",
    "else:\n",
    "    print(\"best_param_vals.npy not found\")\n",
    "\n",
    "# TODO: add custom plots using saved outputs in output_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Calculate PWV with the 0D model\n",
    "\n",
    "Add your preferred PWV computation here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute PWV from 0D outputs\n",
    "# pwv_0d = compute_pwv(sim_helper, ...)\n",
    "# pwv_0d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Switch selected vessels to 1D and generate C++ model\n",
    "\n",
    "Update vessel arrays for 1D coupling and regenerate a C++ model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update vessel array to set specific vessels to 1D in PhLynx\n",
    "\n",
    "inp_data_dict_cpp = dict(inp_data_dict)\n",
    "inp_data_dict_cpp.update({\n",
    "    \"model_type\": \"cpp\",\n",
    "    \"couple_to_1d\": True,\n",
    "    \"cpp_generated_models_dir\": str(generated_models_dir / file_prefix),\n",
    "    \"cpp_1d_model_config_path\": \"/path/to/input1d.dat\",  # TODO: update\n",
    "})\n",
    "\n",
    "# Generate C++ model with 1D coupling\n",
    "success_cpp = generate_with_new_architecture(False, inp_data_dict_cpp)\n",
    "if not success_cpp:\n",
    "    raise RuntimeError(\"C++ model generation failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) Run the C++ model\n",
    "\n",
    "Use `subprocess` to run the compiled binary for the 0D-1D hybrid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# TODO: update binary path and arguments\n",
    "cpp_run_dir = Path(inp_data_dict_cpp.get(\"cpp_generated_models_dir\", generated_models_dir / file_prefix))\n",
    "cpp_binary = cpp_run_dir / \"run_model\"  # placeholder\n",
    "\n",
    "if cpp_binary.exists():\n",
    "    result = subprocess.run([str(cpp_binary)], cwd=str(cpp_run_dir), capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "else:\n",
    "    print(f\"C++ binary not found: {cpp_binary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Load and plot 0D-1D hybrid results\n",
    "\n",
    "Load the hybrid outputs and compare them to the 0D results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update with real hybrid output file(s)\n",
    "hybrid_output_csv = cpp_run_dir / \"hybrid_outputs.csv\"\n",
    "\n",
    "if hybrid_output_csv.exists():\n",
    "    hybrid = pd.read_csv(hybrid_output_csv)\n",
    "    time_col = \"time\"  # TODO: update\n",
    "    hybrid_var = \"aortic_root/u\"  # TODO: update\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(t, y[2], label=\"0D\")\n",
    "    plt.plot(hybrid[time_col], hybrid[hybrid_var], label=\"0D-1D hybrid\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(hybrid_var)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Hybrid output not found: {hybrid_output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15) PWV comparison (0D vs 0D-1D)\n",
    "\n",
    "Compute PWV for the hybrid outputs and compare with the 0D model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute and compare PWV for hybrid outputs\n",
    "# pwv_hybrid = compute_pwv_from_hybrid(hybrid)\n",
    "# print(\"PWV 0D:\", pwv_0d)\n",
    "# print(\"PWV hybrid:\", pwv_hybrid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16) Concise-call hints (commented)\n",
    "\n",
    "Below are shorter, user-friendly call patterns you can aim to implement as wrappers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_model(file_prefix, model_type=\"cellml_only\")\n",
    "# sim = run_simulation(model_path, dt=0.01, sim_time=2.0, pre_time=20.0)\n",
    "# plot_outputs(sim, [\"aortic_root/u\", \"aortic_root/v\"])\n",
    "# obs_path = create_obs_data(data, protocol_info, predictions)\n",
    "# params_path = create_params_for_id(params_df)\n",
    "# sa_results = run_sensitivity(model_path, obs_path, params_path, output_dir)\n",
    "# best_params = pick_top_parameters(sa_results, top_k=2)\n",
    "# param_id = calibrate_model(model_path, obs_path, params_path, method=\"genetic_algorithm\")\n",
    "# run_cpp_model(cpp_run_dir)\n",
    "# hybrid = load_hybrid_outputs(cpp_run_dir)\n",
    "# compare_outputs(uncalibrated, hybrid)\n",
    "# compare_pwv(pwv_0d, pwv_hybrid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCOR",
   "language": "python",
   "name": "opencor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
