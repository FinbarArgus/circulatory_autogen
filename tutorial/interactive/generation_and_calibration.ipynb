{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation and Calibration (3compartment -> no_arm_CVS)\n",
    "\n",
    "This notebook walks through the end-to-end workflow for generating, simulating, and calibrating a 3compartment model, then extending to a 0D-1D hybrid.\n",
    "\n",
    "## Big Picture Aim\n",
    "\n",
    "We want to be able to easily generate system models from CellML, tailored towards a specific use-case (number of vessels, 0D or 1D, complexity, etc), then calibrate the model to clinical data. Calibration is often difficulat with a large parameter set, therefore, we use sensitivity analysis to find the most important parameters to calibrate.\n",
    "\n",
    "## Steps overview\n",
    "1. Set up imports and paths.\n",
    "2. Open vessel array file for 3compartment (switch to no_arm_CVS) in PhLynx.\n",
    "3. Generate CellML model from PhLynx (saved to Downloads).\n",
    "4. Load the model with `SimulationHelper`.\n",
    "5. Plot ground-truth data vs. uncalibrated outputs.\n",
    "6. Add arm vessels in PhLynx and regenerate. (We need arms to compare against finger pressure measurement!)\n",
    "7. Set the ground truth data for calibration.\n",
    "8. Create a parameter identification object from Python.\n",
    "9. Run sensitivity analysis over a large parameter set.\n",
    "10. View sensitivity analysis plots.\n",
    "11. Add an extra feature to fit to.\n",
    "12. Choose the most influential parameters (e.g., top 2).\n",
    "13. Run parameter identification (genetic algorithm).\n",
    "14. Review calibration outputs.\n",
    "15. Calculate PWV with the 0D model.\n",
    "16. Switch selected vessels to 1D and generate C++ model.\n",
    "17. Run the C++ model.\n",
    "18. Load and plot 0D-1D hybrid results.\n",
    "19. Compare PWV for 0D vs 0D-1D.\n",
    "20. Concise-call hints (commented).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![optional caption](diagram_cvs_model_without_left_arm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Set up imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Core imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use('module://ipykernel.pylab.backend_inline')\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import opencor as oc\n",
    "except:\n",
    "    print('opencor not available, open this jupyter notebook with a python version that has opencor installed')\n",
    "    exit()\n",
    "\n",
    "print(\"Imports done\")\n",
    "\n",
    "# Ensure local src is importable\n",
    "project_root = Path(\"/home/farg967/Documents/git_projects/circulatory_autogen\")\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "# Set up paths\n",
    "resources_dir = project_root / \"resources\" # TODO: change to the downloads dir if using Phlynx output directly\n",
    "generated_models_dir = project_root / \"generated_models\"\n",
    "param_id_output_dir = project_root / \"param_id_output\"\n",
    "this_dir = project_root / \"tutorial\" / \"interactive\"\n",
    "downloads_dir = Path.home() / \"Downloads\"\n",
    "\n",
    "print(\"Paths done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Open vessel array in PhLynx (manual)\n",
    "\n",
    "- Open the 3compartment  vessel array in PhLynx [LINK_TO_PHLYNX].\n",
    "- Save/export the vessel array so it is ready for CellML generation. [TO_REPLACE_WITH_GENERATED_CELLML_MODEL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generate CellML in PhLynx (manual)\n",
    "\n",
    "- In PhLynx, generate the CellML model for the edited vessel array.\n",
    "- The exported file is typically saved to `~/Downloads`.\n",
    "- Note the exported filename (e.g., `3compartment.cellml`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.utility_funcs import get_default_inp_data_dict\n",
    "import pprint\n",
    "# Model identifiers\n",
    "model_name = \"cvs_model\"\n",
    "# file_prefix = \"3compartment\" \n",
    "file_prefix = model_name+\"_0d\" \n",
    "input_param_file = f\"{file_prefix}_parameters.csv\"\n",
    "\n",
    "# Base user inputs (this shows all the settings that can be changed)\n",
    "inp_data_dict = get_default_inp_data_dict(file_prefix, input_param_file, resources_dir)\n",
    "\n",
    "print('inp_data_dict set')\n",
    "pprint.pprint(inp_data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.script_generate_with_new_architecture import generate_with_new_architecture\n",
    "import shutil\n",
    "\n",
    "# Generate directly from resources CSVs\n",
    "success = generate_with_new_architecture(inp_data_dict=inp_data_dict)\n",
    "if not success:\n",
    "    raise RuntimeError(\"Model generation failed\")\n",
    "else:\n",
    "    print('Model generation successful')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Load the model with SimulationHelper\n",
    "\n",
    "Use the solver wrapper to load the CellML model and prepare a simulation helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solver_wrappers import get_simulation_helper_from_inp_data_dict\n",
    "\n",
    "# Simulation settings\n",
    "inp_data_dict[\"sim_time\"] = 2 # the 2 seconds we care about\n",
    "inp_data_dict[\"pre_time\"] = 20.0 # simulate for 20 seconds to get to periodic steady state\n",
    "\n",
    "sim_helper = get_simulation_helper_from_inp_data_dict(inp_data_dict)\n",
    "\n",
    "# Run once and plot a few representative variables\n",
    "sim_helper.run()\n",
    "variables_to_plot = [\n",
    "    \"venous_svc/u\",\n",
    "    \"A_aorta_ascending_1/v\",\n",
    "    \"A_aorta_ascending_1/u\",\n",
    "    \"heart/u_rv\",\n",
    "]\n",
    "\n",
    "y = sim_helper.get_results(variables_to_plot, flatten=True)\n",
    "t = sim_helper.get_time()\n",
    "\n",
    "##### Plotting #####\n",
    "\n",
    "plot_dir = Path(param_id_output_dir) / \"quicklooks\"\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, sharex=True, figsize=(8, 6))\n",
    "axs = axs.flatten()\n",
    "for idx, (ax, series, name) in enumerate(zip(axs, y, variables_to_plot)):\n",
    "    ax.plot(t, series)\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir / \"uncalibrated_outputs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Plot ground-truth data vs uncalibrated outputs\n",
    "\n",
    "Load the ground-truth data and compare it to the uncalibrated simulation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update with your ground-truth data file\n",
    "# Example assumes a CSV with a time column and measurement columns\n",
    "\n",
    "ground_truth_file = os.path.join(this_dir, \"resources\", \"aorta_pressure_temp.txt\")\n",
    "if os.path.exists(ground_truth_file):\n",
    "    gt = pd.read_csv(ground_truth_file, sep=\"\\t\")\n",
    "\n",
    "    time_col = \"time_s\"\n",
    "    var_col = \"pressure_mmHg\"\n",
    "\n",
    "    time_gt = gt[time_col].to_numpy()\n",
    "    pressure_pa = gt[var_col].to_numpy() * 133.322  # mmHg -> Pa\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(time_gt, pressure_pa, label=\"ground truth\")\n",
    "    plt.plot(t, y[2], label=\"uncalibrated\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Pressure [Pa]\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Ground-truth file not found: {ground_truth_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Add arm vessels in PhLynx (manual)\n",
    "\n",
    "- Add arm vessels in PhLynx.\n",
    "- Regenerate the CellML model.\n",
    "- If you exported a new CellML file, re-run the copy/generation cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Create a parameter identification object which will be used to set up your calibration problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from param_id.paramID import CVS0DParamID\n",
    "\n",
    "# first create a a param id object which will be used to set up out calibration problem\n",
    "solver_info = {\n",
    "    \"dt\": 0.01,\n",
    "    \"pre_time\": 20.0,\n",
    "    \"sim_time\": 2.0,\n",
    "    \"solver_type\": \"cvode\",\n",
    "    \"solver_options\": {\"atol\": 1e-6, \"rtol\": 1e-6},\n",
    "}\n",
    "# TOSO SOLVER INFO NOT USED\n",
    "\n",
    "param_id = CVS0DParamID(\n",
    "    model_path=inp_data_dict[\"model_path\"],\n",
    "    model_type=\"cellml_only\",\n",
    "    param_id_method=\"genetic_algorithm\",\n",
    "    file_name_prefix=file_prefix # name here only needed for saved files\n",
    ")\n",
    "\n",
    "# you could also have called the below to use the inp_data_dict created previously\n",
    "# TODO probably change to the below\n",
    "# param_id = CVS0DParamID.init_from_dict(inp_data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Set the observable data that you want to calibrate towards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.obs_data_helpers import ObsDataCreator\n",
    "\n",
    "# now create the obs data creator object for creating a dictionary that contains the data you will fit towards\n",
    "obs_data_creator = ObsDataCreator()\n",
    "\n",
    "# Protocol info (this defines your times and changes of inputs in the experiment)\n",
    "pre_times = [[20]]\n",
    "sim_times = [[time_gt[-1]]]\n",
    "obs_dt = time_gt[1]-time_gt[0]\n",
    "params_to_change = {}\n",
    "obs_data_creator.add_protocol_info(pre_times, sim_times, params_to_change)\n",
    "\n",
    "# Currently we fit to features from the trace, you can change this to fit to the series itself\n",
    "# TODO make sure Mohammad's code is working for the SA for this.\n",
    "\n",
    "fit_to_series = False\n",
    "\n",
    "if fit_to_series: \n",
    "    # Data items (fill with your actual observation series)\n",
    "    # Example placeholder (replace with real data)\n",
    "    # input entries into add_data_item\n",
    "    entry = {\n",
    "        \"variable\": \"P aortic root\",\n",
    "        \"name_for_plotting\": \"$P_{ao}$\",\n",
    "        \"operation\": None, # tells what operation to do on the operands to compare to value\n",
    "        \"operands\": [\"A_aorta_ascending_1/u\"],\n",
    "        \"unit\": \"Pa\", \n",
    "        \"weight\": 1.0, # allows you to weight the data item differently\n",
    "        \"value\": pressure_pa,\n",
    "        \"std\": pressure_pa*0.1, # assume 10% Coefficient of variation for now\n",
    "        \"obs_dt\": obs_dt,  \n",
    "    }\n",
    "    obs_data_creator.add_data_item(entry)\n",
    "\n",
    "else:\n",
    "    # add an entry for just fitting the mean of the pressure\n",
    "    entry = {\n",
    "        \"variable\": \"P aortic root mean\",\n",
    "        \"name_for_plotting\": \"$P_{aoMean}$\",\n",
    "        \"operands\": [\"A_aorta_ascending_1/u\"],\n",
    "        \"operation\": \"mean\",\n",
    "        \"unit\": \"Pa\",\n",
    "        \"value\": np.mean(pressure_pa),\n",
    "        \"std\": 200, # assumed std of the mean pressure\n",
    "        \"obs_dt\": obs_dt,\n",
    "    }\n",
    "    obs_data_creator.add_data_item(entry)\n",
    "    \n",
    "\n",
    "obs_data_dict = obs_data_creator.get_obs_data_dict()\n",
    "\n",
    "# pprint.pprint(obs_data_dict)\n",
    "\n",
    "# now add the obs to the param id object\n",
    "param_id.set_ground_truth_data(obs_data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Create params_for_id.csv from Python\n",
    "\n",
    "Define the parameter bounds for identification in a CSV file. Use the same schema as `resources/3compartment_params_for_id.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessels_to_calibrate_stiffness = [\"K_tube_A_aorta_ascending_1\", \"K_tube_A_aorta_ascending_2\", \n",
    "                               \"K_tube_A_aorta_ascending_3\", \"K_tube_A_aorta_ascending_4\",\n",
    "                               \"K_tube_A_aortic_arch_1\", \"K_tube_A_aortic_arch_2\", \"K_A_tube_aortic_arch_3\"]\n",
    "\n",
    "params_for_id_dict = [\n",
    "    {\n",
    "        \"vessel_name\": \"global\",\n",
    "        \"param_name\": \"q_lv_init\",\n",
    "        \"min\": 400e-6,\n",
    "        \"max\": 2500e-6,\n",
    "        \"name_for_plotting\": \"q_{sbv}\",\n",
    "    },\n",
    "    {\n",
    "        \"vessel_name\": vessels_to_calibrate_stiffness,\n",
    "        \"param_name\": \"E\",\n",
    "        \"min\": 8e+4,\n",
    "        \"max\": 4e+5,\n",
    "        \"name_for_plotting\": \"E_{ao}\",\n",
    "    },\n",
    "    {\n",
    "        \"vessel_name\": vessels_to_calibrate_stiffness[1],\n",
    "        \"param_name\": \"E\",\n",
    "        \"min\": 2e+4,\n",
    "        \"max\": 6e+5,\n",
    "        \"name_for_plotting\": \"E_{ao_2}\",\n",
    "    }\n",
    "]\n",
    "\n",
    "print(params_for_id_dict)\n",
    "# TODO the below might be easier to understand\n",
    "# param_id.add_param_for_id(module_name, param_name, min, max, name_for_plotting)\n",
    "# param_id.add_param_for_id(module_name, param_name, min, max, name_for_plotting)\n",
    "\n",
    "\n",
    "# now add the params to the param id object\n",
    "param_id.set_params_for_id(params_for_id_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Sensitivity analysis\n",
    "\n",
    "Run Sobol sensitivity analysis over a large parameter set and save outputs to a defined directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensitivity_analysis.sensitivityAnalysis import SensitivityAnalysis\n",
    "import shutil\n",
    "\n",
    "sa_output_dir = Path(param_id_output_dir) / \"sensitivity\" / file_prefix\n",
    "if sa_output_dir.exists():\n",
    "    shutil.rmtree(sa_output_dir) # remove the directory if it exists\n",
    "sa_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "sa_options = {\n",
    "    \"method\": \"sobol\",\n",
    "    \"sample_type\": \"saltelli\",\n",
    "    \"num_samples\": 16, # change to 256\n",
    "    \"output_dir\": str(sa_output_dir),\n",
    "}\n",
    "\n",
    "sa_agent = SensitivityAnalysis.init_from_dict(inp_data_dict)\n",
    "\n",
    "\n",
    "\n",
    "sa_agent.set_ground_truth_data(obs_data_dict)\n",
    "sa_agent.set_params_for_id(params_for_id_dict)\n",
    "sa_agent.set_sa_options(sa_options)\n",
    "\n",
    "sa_agent.run_sensitivity_analysis(sa_options)\n",
    "sa_output_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) View the sensitivity analysis plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Display the plots from the sensitivity analysis\n",
    "plot_files = [file_path for file_path in sa_output_dir.glob(\"*.png\")]\n",
    "for plot_file in plot_files:\n",
    "    display(Image(filename=str(plot_file)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Now add your own extra feature to fit to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====  this is an example of how to add a custom feature to the obs data creator =====\n",
    "# this feature calculates the pressure at one point in time. \n",
    "# Modify this function to extract whatever feature you want! Max? Min? weights of a certain basis? Anything you want.\n",
    "\n",
    "# Create your own feature to fit to\n",
    "def my_extra_feature(time, pressure):\n",
    "    half_idx = len(time) // 2\n",
    "    return pressure[half_idx]\n",
    "\n",
    "sa_agent.add_user_operation_func(my_extra_feature)\n",
    "param_id.add_user_operation_func(my_extra_feature)\n",
    "\n",
    "extra_entry = {\n",
    "    \"variable\": \"P aortic root half time\",\n",
    "    \"name_for_plotting\": \"$P_{aoHalf}$\",\n",
    "    \"operands\": [\"time\",\"A_aorta_ascending_1/u\"], # these need to correspond to the operands in my_extra_feature\n",
    "    \"operation\": \"my_extra_feature\",\n",
    "    \"unit\": \"Pa\",\n",
    "    \"value\": my_extra_feature(time_gt, pressure_pa), # this uses your function to get the value you want to fit to from the ground truth data\n",
    "    \"std\": 200, # assumed std of the pressure\n",
    "}\n",
    "\n",
    "obs_data_creator.add_data_item(extra_entry)\n",
    "obs_data_dict = obs_data_creator.get_obs_data_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sa_agent.set_ground_truth_data(obs_data_dict)\n",
    "\n",
    "# remove the old results before running.\n",
    "if sa_output_dir.exists():\n",
    "    shutil.rmtree(sa_output_dir) # remove the directory if it exists\n",
    "sa_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sa_agent.run_sensitivity_analysis(sa_options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display the plots from the sensitivity analysis\n",
    "plot_files = [file_path for file_path in sa_output_dir.glob(\"*.png\")]\n",
    "for plot_file in plot_files:\n",
    "    display(Image(filename=str(plot_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Choose influential parameters\n",
    "\n",
    "Review the sensitivity analysis outputs (plots/arrays) to choose the most influential parameters (e.g., top 2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: inspect SA outputs in sa_output_dir and pick top parameters\n",
    "# Example placeholder list:\n",
    "# most_influential_params = [\n",
    "#     \"global/q_lv_init\"\n",
    "# ]\n",
    "# most_influential_params\n",
    "\n",
    "most_influential_params = sa_agent.choose_most_impactful_params_sobol(top_n=1, index_type='ST', criterion='max', threshold=0.05, use_threshold=True)\n",
    "most_influential_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) Parameter identification (genetic algorithm)\n",
    "\n",
    "Use the genetic algorithm to calibrate model parameters.\n",
    "\n",
    "$$\n",
    "\\theta^{\\star} = \\arg\\min_{\\theta \\in \\Theta} \\; \\sum_{i=1}^{N} w_i \\left\\lVert \\frac{z_i(\\theta) - \\hat{z_i}}{\\sigma_i} \\right\\rVert^2\n",
    "$$\n",
    "\n",
    "where $\\theta^{\\star}$ is the best fit parameter vector, $\\Theta$ is your parameter space, defined by the min and max you set in params_for_id_dict, $z_i$ are your output features, $\\hat{z_i}$ are your ground truths for those features, $\\sigma_i$ are your feature standard deviations, and $w_i$ are the weights for each feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from param_id.paramID import CVS0DParamID\n",
    "\n",
    "inp_data_dict[\"param_id_method\"] = \"genetic_algorithm\"\n",
    "param_id.set_param_id_method(inp_data_dict[\"param_id_method\"])\n",
    "\n",
    "# Optimiser options (adjust as needed)\n",
    "optimiser_options = {\n",
    "    \"num_calls_to_function\": 1000,\n",
    "    \"cost_convergence\": 0.001,\n",
    "    \"max_patience\": 10,\n",
    "    \"cost_type\": \"MSE\",\n",
    "}\n",
    "\n",
    "param_id.set_optimiser_options(optimiser_options)\n",
    "param_id.set_ground_truth_data(obs_data_dict)\n",
    "\n",
    "# update params for id dict with most influential params\n",
    "\n",
    "param_id.set_params_for_id(params_for_id_dict)\n",
    "\n",
    "# TODO I am up to here for debugging\n",
    "# TODO protocol info isn't getting created correctly.\n",
    "\n",
    "# Run calibration\n",
    "param_id.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot best fit\n",
    "param_id.simulate_with_best_param_vals()\n",
    "param_id.plot_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Review calibration outputs\n",
    "\n",
    "The calibration process saves plots and arrays in the parameter ID output directory. Use this section to view the plots. You can also make your own plots with the saved outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(param_id.output_dir)\n",
    "print(\"Outputs saved to:\", output_dir)\n",
    "\n",
    "# Example: load best parameters\n",
    "best_params_path = output_dir / \"best_param_vals.npy\"\n",
    "if best_params_path.exists():\n",
    "    best_params = np.load(best_params_path)\n",
    "    best_params\n",
    "else:\n",
    "    print(\"best_param_vals.npy not found\")\n",
    "\n",
    "# Display the plots from the param id\n",
    "plot_files = [file_path for file_path in output_dir.glob(\"*.png\")]\n",
    "for plot_file in plot_files:\n",
    "    display(Image(filename=str(plot_file)))\n",
    "    \n",
    "\n",
    "# === Here you can make your own custom plots using saved outputs in output_dir ===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15) Calculate PWV with the 0D model\n",
    "\n",
    "Add your preferred PWV computation here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute PWV from 0D outputs\n",
    "# pwv_0d = compute_pwv(sim_helper, ...)\n",
    "# pwv_0d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16) Switch selected vessels to 1D and generate C++ model\n",
    "\n",
    "Update vessel arrays for 1D coupling and regenerate a C++ model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vess_1d_list.extend(['A_axillary_L', 'A_brachial_L', 'A_radial_L', 'A_ulnar_L',\n",
    "                     'A_superficial_palmar_arch_L_1', 'A_superficial_palmar_arch_L_2',\n",
    "                     'A_comm_palmar_digital_L_1', 'A_comm_palmar_digital_L_2', 'A_comm_palmar_digital_L_3'])\n",
    "    \n",
    "convert_0d_to_1d(model_name_ext, resources_dir, input_param_file, folder_hyb=None, vess_1d_list=vess_1d_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17) Run the C++ model\n",
    "\n",
    "Use `subprocess` to run the compiled binary for the 0D-1D hybrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# TODO: update binary path and arguments\n",
    "cpp_run_dir = Path(inp_data_dict_cpp.get(\"cpp_generated_models_dir\", generated_models_dir / file_prefix))\n",
    "cpp_binary = cpp_run_dir / \"run_model\"  # placeholder\n",
    "\n",
    "# we need a step here to call the building of the cpp model\n",
    "# OR WE DO THIS IN TERMINAL AND PROVIDE INSTRUCTIONS\n",
    "\n",
    "\n",
    "# now run the cpp executable.\n",
    "if cpp_binary.exists():\n",
    "    result = subprocess.run([str(cpp_binary)], cwd=str(cpp_run_dir), capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "else:\n",
    "    print(f\"C++ binary not found: {cpp_binary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18) Load and plot 0D-1D hybrid results\n",
    "\n",
    "Load the hybrid outputs and compare them to the 0D results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update with real hybrid output file(s)\n",
    "hybrid_output_csv = cpp_run_dir / \"hybrid_outputs.csv\"\n",
    "\n",
    "if hybrid_output_csv.exists():\n",
    "    hybrid = pd.read_csv(hybrid_output_csv)\n",
    "    time_col = \"time\"  # TODO: update\n",
    "    hybrid_var = \"aortic_root/u\"  # TODO: update\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(t, y[2], label=\"0D\")\n",
    "    plt.plot(hybrid[time_col], hybrid[hybrid_var], label=\"0D-1D hybrid\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(hybrid_var)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Hybrid output not found: {hybrid_output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19) PWV comparison (0D vs 0D-1D)\n",
    "\n",
    "Compute PWV for the hybrid outputs and compare with the 0D model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute and compare PWV for hybrid outputs\n",
    "# pwv_hybrid = compute_pwv_from_hybrid(hybrid)\n",
    "# print(\"PWV 0D:\", pwv_0d)\n",
    "# print(\"PWV hybrid:\", pwv_hybrid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCOR",
   "language": "python",
   "name": "opencor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
